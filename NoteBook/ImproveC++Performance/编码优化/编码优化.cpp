
// !! 编码优化

对多数人而言，如果我们的讨论仅仅围绕特定领域或特定应用程序, 将是毫无意义的，因为对于这类讨论，其受益者仅是那些工作在相关领域或开发相关应用程序的程序员。
为了引起更多读者的共鸣, '我们必须设法解决遍布于程序设计各个领域以及随机出现在任意应用程序中的性能问题'，而且，我们不应对问题的所属领域做任何假设。

虽然性能问题的表现形式多种多样，但这些问题可以被划分为有限类。每个种类代表一类等价的性能缺陷。对于同一种问题，表面上看来可能不尽相同，但其本质却大同小异。
举例来说，'冗余计算就具有多种表现形式'。考虑如下循环不变式的计算:

for(int i = 0; i < 100; i++)
{
    a[i] = m*n;
}

每次迭代循环都会重复计算 m＊n 的值。如果将不变式移出循环，就可避免重复计算:

int k = m *n;
for(int i = 0; i <100; i++)
{
    a[i] = k;
}


计算方面的浪费还有其他表现形式。如下例所示，每个例程均需要访问当前线程的私有信息。pthread_getspecific() 函数返回一个指向线程私有数据结构的指针。
函数 f() 和 g() 都需要访问该私有数据，所以它们都要调用 pthread_getspecific() :

static pthread_key_t global_key;

void f()
{
    void * x = pthread_getspecific(global_key);
    g();
    ...
}

void g()
{
    void *y = pthread_getspecific(global_key);
    ...
}

在同一个线程中，函数 f() 在执行时调用了函数 g() ，因此在同一个流程中 pthread_getspecific() 将被调用两次，这无疑是一种计算浪费。而调用
pthread_getspecific() 的代价高昂，这种计算浪费使情况变得更糟。我们可以将 pthread_getspecific() 的调用结果直接传递给g（），消除二次调用:

static pthread_key_t global_key;

void f()
{
    void * x = pthread_getspecific(global_key);
    g();
    ...
}

void g(void * y)
{
    ...
}


之前分析的两个例子虽表现形式不同，但它们都属于同一种低效的性能缺陷：冗余计算。即重复计算已知的结果：第一个例子中(m＊n)的值，以及第二个例子中
pthread_getspecific() 的返回值。

本章重点分析应用程序编码阶段出现的性能问题。由于性能问题的多样性，我们不会给出各类问题的实例。我们将着重讨论那些已经被发现且较为突出的性能问题。这些问题规模通常
较小：在其解决方法中，所包含的代码量都很少。将常量放置在循环之外就是此类编码优化的一个示例。您并不需要全面掌握程序设计，只需要理解 for 循环语句的相关知识即可。

'同深层次的设计问题相比，性能方面的编码问题更容易解决'。当我们首次加入 Web 服务器开发团队时，并不需要负责深层次的设计优化问题。在此阶段，我们对服务器整体设计的理
解还远远不够，因此无法对其进行大幅修改。但我们却能很容易地发现先前示例所描述的 pthread_getspecific() 的低效性问题。在响应 HTTP 请求的过程中，这个调用将至少执
行 100 次。我们通过将返回值传递给其他需要的例程，轻而易举地将服务器的吞吐量提高了 10%。


// !! 缓存

在现代处理器中，缓存经常与处理器中的数据缓存和指令缓存联系在一起。但缓存出现的时机与场合却更加广泛，包括应用程序的编码和设计阶段。

'缓存主要用来存储使用频繁而且代价高昂的计算结果，这样就可以避免对这些结果的重复计算'。

在编码的舞台上，缓存时机的检测和实施更加容易。'循环内对常量表达式求值是一种常见的低性能问题'，如下例所示:

for(...; !done; ...)
{
    done = patternsMatch(pat1, pat2, isCaseInsensitive());
}

函数 patternMatch() 对两个字符串进行匹配，第三个参数用来指定是否区分大小写，该参数由函数 isCaseSensitive() 生成，其作用只是简单地区分大小写敏感的UNIX平台
和大小写不敏感的PC平台，因此其返回值是固定的。'由于函数返回值独立于循环体，且不随迭代而改变，因此对该函数的调用应放在循环之外':

bool isSensitive = isCaseSensitive();
for(...; !done; ...)
{
    done = patternsMatch(pat1, pat2, isSensitive);
}


这样为了区分大小写，我们只需进行一次计算，其结果缓存在局部变量中以便重复使用。


// !! 预先计算

预先计算和缓存联系紧密。当缓存某个计算的结果时，需要付出的代价是在对性能有重大影响的关键路径上完成一次计算。如果采用预先计算，那么甚至连这一次计算也可免了。
'将预先计算放置在影响性能的关键路径之外(例如初始化阶段)，就可以避免在性能关键路径上进行代价高昂的计算'。

回到 Web 服务器实现的示例中，Web 服务器将相当的时间花费在字符串处理上，如果可以提高字符串处理的速度，那么服务器的性能将得到显著提升。将字符串或字符转换为大写
是经常会遇到的字符串处理任务。如果浏览器给服务器发送一个 “Accept：” 请求报头，服务器必须能识别，而不管报头的字母是大写还是小写，不必对 “accept：”，“AcCePt：
”或其他大小写混合的字符串进行区分。

由于函数 memcmp(header，"ACCEPT："，7)区分大小写，因此在调用 memcmp() 函数前应先将报头字符串转化为大写格式。

方法如下:

for(char *p = header; *p; p++)
{
    *p = toupper(*p);
}

if(0 == memcmp(header,"ACCEPT:",7))
{
    ...
}

'在影响性能的关键路径上，反复调用 toupper() 的代价是无法接受的'，即便将其作为内联函数实现，仍将包含如下形式的条件语句:

return (c > 'a' && c < 'z') ? c - ('a' - 'A'):c;

这是针对 ASCII 的实现。而针对 EBCDIC 字符集（EBCDIC字母表的顺序不是不连续的）的实现会更加复杂。

如果希望避免为可能的库函数调用或内联条件语句的开销，可以预先计算出每个可能出现的字符相应的大写值:

void initLookupTable()
{
    for(int i = 0; i < 256; i++)
    {
        uppercaseTable[i] = toupper(i);
    }
}

由于 uppercaseTable 在起始阶段完成初始化，所以 islower()  和 toupper() 代价是无须考虑的，其性能也就不成问题。

现在只需执行两条指令即可将字符转化为大写格式，这将显著提高字符串操作的效率:

for(char *p = header; *p; p++)
{
    *p = uppercaseTable[*p];
}

if(0 == memcmp(header,"ACCEPT:",7))
{
    ...
}


通过这种方式，可以预先计算出在性能关键路径上出现的其他字符处理函数查询表： islower() 、isspace() 、isdigit() 等等。


// !! 降低灵活性

'作为某一领域的专家，经常需要做一些简化问题的假设以提高性能'。

通常情况下，当客户端发起请求时 Web 服务器需要知道其 IP 地址。IP地址用点分十进制数来表示，比如，9.37.37.205。起初，对于每一次请求，程序都分配足够多的堆存储空
间用以容纳客户端的 IP 地址。请求处理结束时再释放该空间。调用函数 new() 和函数 delete() 来处理堆存储空间的代价很高，尤其是每次请求均需调用这两个函数的情况将更
加糟糕。'尽管使用内存池可以减轻负担，但还是无法完全消除对 new() 和 delete() 的调用'。

如果 IP 地址的长度没有限制，那么除了动态分配空闲内存空间外别无选择。但是，作为 TCP/IP 方面的专家，必然知道当前 IP 地址的长度不会超过15字节。

最长的地址形式为：

xxx.xxx.xxx.xxx

如果再增加一个终结符 NULL，则长度变为 16 字节。下一代 IP 地址(IPv6)的长度虽然有所增加，但总归是有限的。'既然 IP 地址的长度是有限的，那么以局部变量的形式将
IP 地址存储在堆栈上会更加有效'。

char clinetIpAddress[256];

在未来很多年内这种做法已经足够好了。尽管 32 字节已经足够，但出于安全方面的考虑我们还是选择了 256 字节。'这个有限的字符数组消除了代价高昂的 new() 和 delete()
调用。为了获得性能的提升而牺牲了永远不会需要的灵活性'。


// !! 80-20 法则：加快常用路径的速度

80-20 法则适用于很多场合：80% 的程序执行只遍历 20% 代码；'80% 的程序运行时间耗费在执行路径的所遇到的 20% 函数上'。80-20 法则有力地证明了过于草率的判断是
一种错误这个观点。如果想到什么就改什么，不仅仅浪费了 80% 的努力，而且也会造成设计的无法修复。


HTTP 规范是一份有 100 页的文档，该文档描述了 Web 服务器必须处理的所有可能的 HTTP 请求。但如今在 Web 上使用的绝大部分HTTP请求是极其简单的。这些请求仅仅是所
有可能的 HTTP 报文头的一个子集。找出这些常见的报文头是很容易的：由于 Microsoft 和 Netscape 共同统治了浏览器市场，我们所要做的就是获取由这两个浏览器所发出的
报文头。这也是 80-20 法则的另一种体现——所有可能的 20% 输入会占用 80% 的时间。


80-20 法则还有另一种表现方式。'我们不仅要将注意力放在程序的典型执行路径上，同时应该充分利用大多数输入数据一般都限制在整个输入空间的狭窄范围里这个事实'，

下面列举一些典型的例子。

if(0 == memcmp("Accept:",headers,7) // 聪明的冒险
|| (0 == memCasecmp("accept:",headers,7)))
{

}

对于 95% 的输入，memcmp() 函数将会返回成功，所以不必调用耗费时间的 memCaseCmp()。

if( e1 || e2 )
{

}

在上面的表达式中，'求值顺序与性能有着莫大的关系'。


// !! 延迟计算

为一个最终可能不需要的计算付出性能代价显然不是明智之举。然而在复杂的代码中这种情况比比皆是。我们不应该执行“只在某种情况下”才需要的昂贵计算，而应该只在必要的时候执
行昂贵计算。'这通常常意味着把计算推迟到真正需要的时候才进行，因此称之为延迟计算'(Lazy Evaluation)。


早在纯 C 程序时代，我们就习惯在程序的开头预先定义所有的变量。'而在 C++ 中，对象的定义会调用构造函数和析构函数，这可能是高成本的'，因为它导致了立即计算-----
而这正是我们所要避免的。'延迟计算原则建议我们推迟对象的定义，直到要使用该对象时再定义'。为不一定用到的构造函数和析构函数付出代价是没有意义的。这听起来很可笑，
实际上却时常发生。

在一个用 C++ 编写的网关程序中，我们有一段运行在 AIX 内核的对程序性能至关重要的代码。这段代码用于交换下行和上行通信适配器的消息。在程序定义的对象中，有一个对象
的构造和析构函数代价很昂贵：

int route(Message *msg)
{
    ExpensiceClass upstream(msg);
    if(goingUpstream)
    {
        // 处理代驾昂贵的对象
    }
    // 此处不使用对象 upstream
    return SUCCESS;
}

使用 upstream 对象的代价很高。原先的代码急于在函数开始时构造该对象，而事实上在程序中只有一半的时间，即消息被交换至上行时才使用它，在另一半时间，即消息被交换至下
行时根本不使用。对于后一种情况，upstream 对象的计算完全是浪费的。更好的办法是在真正需要 upstream 对象的地方定义它:

int route(Message *msg)
{
    if(goingUpstream)
    {
        ExpensiceClass upstream(msg);
        // 处理代驾昂贵的对象
    }
    // 此处不使用对象 upstream
    return SUCCESS;
}


另一条关于延迟计算的重要结论： '不仅应该将对象的创建推迟至合适的位置，而且应该直到具备了一个有效创建操作所必需的全部条件后，再创建对象'。

例如:

void f()
{
    string s;// 1
    ...
    char *p = "Message";// 2
    s =p;// 3
    ...
}


在语句 1 中，我们调用默认构造函数 String::String() 创建了 String 对象 s，之后在语句 3 中我们赋予 s 真实内容。直到执行完语句 3，对象 s 才算真正创建完成
，因此这是一种低效的构造。

它需要以下操作：

● 默认的string构造函数——在语句1中。
● 赋值运算符——在语句3中。

延迟计算原则可以将上述操作缩减为仅调用一次构造函数。我们将 String 型对象 s 的构造推迟到已具备必需条件后实现。


void f()
{
    ...
    char *p = "Message";// 2
    string s(p);
    ...
}

通过推迟构造 s，我们实现了一步构造——这无疑更为高效。


// !! 无用计算

延迟计算是指那些不总是必须执行的计算, 至于哪些计算是必须执行的与程序的执行流程有关，而'无用计算是指那些根本无须执行的计算'。无论执行流程如何，这些计算结果从不使
用，因此它们是完全没有意义的。


一个关于无用计算的精妙例子是成员对象的无用初始化。

class Student
{
public:
    Student(char *nm);

private:
    string name;
};

Student 类构造函数将输入的字符指针转换成一个代表学生姓名的 string 对象:

'C++ 保证在 Student 的构造函数体执行之前，所有的成员对象已经创建完成，此处即 string 型的 name 对象'。既然我们没有显式地告诉编译器如何构造它，编译器就插入
了对 string 默认构造函数的调用。该调用在 Student 的构造函数体执行之前进行。在构造函数体之后执行以下代码:

name = nm;

赋值操作实际上清除了 name 对象之前的内容。我们从未使用过编译器调用的 string 默认构造函数的结果。'通过在 Student 的构造函数初始化列表中显式指明 string 构造
函数，可以避免这种无效计算':

Student::Student(char *nm):name(nm)
{

}

由于我们明确告诉编译器使用哪个 string 构造函数，编译器将不再隐式地调用 string 默认构造函数。因此我们实现了一步完成 string 成员对象的构造。


// !! 系统体系结构


内存访问的代价差别很大。在某个特定的 RISC 体系结构中，若数据位于数据缓存中，那么访问它需要耗费一个 CPU 周期；若位于主存中(缓存失败)，则需要 8 个CPU周期；
若位于硬盘上(页面错误)，则需要 400，000 个 CPU 周期。虽然具体的数值会发生变化，但对于不同的处理器体系结构，周期数在总的关系上是一致的:'缓存成功、缓存失败和
页面错误之间的速度相差多个数量级'。

当访问数据时，最先搜索的是数据缓存。若数据不在缓存中，硬件产生缓存失败信号，该信号会从 RAM 或硬盘加载数据至缓存中。'缓存以缓存行为单位，通常加载比我们所寻找的
特定数据项更大的一块数据'。这样的话，在 4 字节整数上的缓存失败可能导致加载 128 字节的缓存行到缓存中。由于相关数据项的位置在内存中很可能相邻，因此这对我们很有用
: 如果随后的指令尝试访问相同缓存行中的其他数据项，那么我们第一次访问该数据时就将缓存成功，能较快地获取数据。我们应该尽可能帮助自己的代码显示这种引用的位置。

以类 X 为例:

class X
{
public:
    X():a(1),c(2){}
    ...

private:
    int a;
    char b[4096];// 缓冲区
    int c;
};

构造函数X::X() 初始化成员 a 和 c。符合标准的编译器将按声明顺序来排列对象 X：成员 a和成员 c被 4096 字节的成员 b 分离，因而不会出现在相同的缓存行内。
当 X::X 构造函数访问 c 时有可能遇到缓存失败。

'既然 a 和 c 被相邻的指令访问，那么我们不妨将它们放在相邻的位置，使得缓存成功率更高'。

class X
{
public:
    X():a(1),c(2){}
    ...

private:
    int a;
    int c;
    char b[4096];// 缓冲区
};

现在a和c更有可能位于相同的缓存行。因为a在c之前被访问，所以当我们需要访问c的时候，基本可以保证c在数据缓存中。


// !! 内存管理

动态分配和释放堆内存的代价比较昂贵。'从性能角度来讲，使用不需要显式管理的内存所产生的代价要低得多'。

被定义成局部变量的对象存放于堆栈上。'该对象所占用的堆栈空间是为相应函数预留的堆栈空间的一部分'，该对象被定义在这个函数范围内。

局部对象的一种办法是使用 new() 和 delete() 来分配和释放堆内存:

void f()
{
    X *xpt = new X();
    ...
    delete xpt;
}

另一种性能更好的选择是定义类型为 X 的局部对象:

void f()
{
    X x;
    ...

}

在后一种实现中，对象 x 驻留在栈上，因而不需要事先为其分配内存，也不需要在函数退出时释放内存。当 f() 返回时，堆栈内存会自动释放，这样就避免了调用
new() 和 delete() 的巨大代价。

成员数据中也存在类似的问题。但这次不是堆和堆栈内存之间的问题，而是选择将指针还是整个对象嵌入到包含对象中的问题:

class Z
{
public:
    Z():xPtr(new X){...}
    ~Z(){delete[] xPtr;}
private:
    X *xPtr;
};


在构造函数中调用 new() 和在析构函数中调用 delete() 所产生的开销明显地增加了对象 Z 的代价。我们可以通过在 Z 中嵌入对象 X 来消除内存管理的代价:

class Z
{
public:
    Z(){...}
    ~Z(){...}
private:
    X x；
};

通过将 X 对象指针替换为X对象，我们用多态使用该成员变量换取了性能。当然，如果真的需要这种灵活性，那么这种优化是不合适的。

再次说明一下：性能就是一种折中的结果。


// !! 库和系统调用

'计算机语言的演变不断地简化了解决复杂问题的设计和编码工作'。随着语言表达能力的发展, 我们可以使用它们来解决更复杂的问题。从理论上来讲，一台使用简单语法的图灵机
和我们今天所拥有的任何编程语言一样强大。我们所谓的强大是指可以使用图灵机编写任何算法。只不过那将是一个非常困难的编程环境，对于汇编语言亦是如此。我们不使用汇编语
言开发 Web 服务器的原因在于其可行性: '使用低级语言开发复杂问题的软件解决方案，非常困难并且很费时间'。

如果想计算两个整数之和，那么这在诸如 C++ 之类的语言中非常简单：

k = i + j;

如果使用汇编语言完成，那么将会有一些微小细节需要我们亲自来处理:

● 将整数i载入到寄存器X；
● 将整数j载入到寄存器Y；
● 将寄存器X和Y中的内容相加；
● 将相加所得结果存储在整数k的内存地址中。


'在高级语言中，所有这些小细节会由编译器处理，我们通常不会去管它。这种简单性使高级语言具备更高的生产力和承担更复杂编程任务的能力'。

隐藏复杂性有很多方法: 硬件隐藏和软件隐藏。'软件隐藏是通过编译器把我们的源代码转换成汇编指令来实现的'。我们也可以亲自实现这种隐藏:将复杂性封装在系统调用、
库和类实现中。


以两个字符串的连接操作为例，我们需要分配足够大的内存，使得它能够包含两个字符串和一个结束符:

{
    char s0;
    char *s1 = "Hello";
    char *s2 = "World";
    s0 = new char[strlen(s1) + strlen(s2) + 1];
    strcpy(s0, s1);
    strcpy(s0,s2);
    ...
}

在 C++ 中，所有这些细节都封装在 string 类的实现中。重载 string 类的“+”操作符可以将我们的客户代码简化为:

{
    string s2("Hello");
    string s3("World");
    string s0 = s1 + s2;
}

当我们步入简明编程的更高层次以后，细节工作其实并没有消失，它们会在其他地方完成。从性能角度来讲，我们不能忽略这些幕后工作。这正是性能工程师区别于其他开发者的地方，
其他开发者唯一关心的是快速地将所需功能放在一起并迅速发布。'而性能开发者必须了解隐藏在代码背后的代价，因为它们可能会对系统性能有深远的影响'。

作为具体的例子，接下来我们研究一下 pthreads 库的实现。该库为用户提供了一个简单的访问 UNIX 平台线程服务的接口。pthread_mutex_lock() 和 pthread_mutex_unlock()。
这两个调用提供互斥锁。如果锁定一个资源，那么就排斥了对该资源的其他访问，直到解锁该资源为止。您无法察觉到的是，在调用 pthread_mutex_lock() 时，pthreads 库的实
现会检查您的线程是否已经拥有锁，这样就防止了死锁。当调用 pthread_mutex_unlock() 时，pthreads 库的实现会检查调用者是否真正拥有锁。除非该线程是之前锁定资源
的那个线程，否则就不能解锁资源。'所有这些必要的出错检查增加了程序执行的路径长度，同时也降低了性能'。

在很多情况下，应用程序对锁的使用可能非常简单，那么此时所有这些开销都是浪费的。您的代码设计可能已经确保了这种前提条件，即要进行锁定的线程目前没有拥有锁，要进行解锁
的线程是之前锁定资源的线程。在这种情况下，可以建立一种简单的锁定模式，该模式是建立在本机操作系统所提供的原始积木块的基础之上的，这显然更为高效。'如果不清楚库的实现
细节，那么您可能还不知道自己正在为一些实际上并不需要的功能而付出性能上的代价'。

我们继续讨论 pthreads 库，下面举一个相关的例子。您可以让每个线程都与一个私有数据区域相关联，该区域可能存储了线程的全局变量。如果需要访问线程的私有数据，那么需
要一个指向内存中该线程区域的指针。调用 pthread_getspecific() 可以得到这个指针。pthreads 库是通过维护当前线程与私有数据之间的关联来实现这种神奇功能的。由于
线程状态可能不断变化，所以这种关联是动态的。必须串行化地访问该集合。因此，pthread_getspecific() 的调用隐藏了内部串行化代码。当获取与给定线程关联的数据时，我们
必须锁定该集合。如果您关心程序的可伸缩性，这可能就是您需要了解的事情。如果多个线程频繁地调用 pthread_getspecific() ，那么串行化逻辑将会因为每个线程各自的锁定
关系而产生可伸缩性阻塞。


// !! 编译器优化

'一个优秀的编译器可以代替开发者实施一些重要的优化，而无须开发者对源代码进行任何干预'。

1. 第一个想到的优化是寄存器分配。当变量位于寄存器中时，载入和存储该变量是最快的。否则，我们将不得不花费很多时钟周期从其他地方获取该变量。如果此时产生一个更
   新，那么还需要将其存回到原来的位置。在这种情况下，如果变量不在缓存中，那么情况会变得更加糟糕。在现代计算机体系结构中，一次单独的内存访问至少需要5个时钟周期。
   如果变量被存储在寄存器中，则这一切可以避免。因为对执行路径中的许多方法都可以使用寄存器分配，所以寄存器分配是一种重要的优化方法。当遇到循环索引变量时，这种优
   化的作用更是特别明显。因为每次循环迭代时都需要访问和更新这些变量。

2. 第二个需要特别注意的优化就是内联

通常情况下, 编译器默认根本不会进行任何优化。这意味着这些重要的性能优化将不会生效——即使在代码中使用了关键字 inline 也无济于事。编译器会自动忽略这些关键字，而
且它经常这样做。为了更好地利用这些优化手段, 必须通过向命令行添加开关'手工打开编译器优化'。

由于针对不同应用程序手工所做的编译器优化都不一样, 所以很难精确量化编译器优化的影响。在我们的经历中, 我们所看到编译器优化对各种应用程序的速度有 20%～40% 的提升
,  这显然是非常诱人的。

// !! 要点

'编码优化在范围上是局部的, 并且不需要对程序的整体设计有深入的理解'。

当您加入到一个正在进行的开发项目中, 并且您对其设计还没有完全理解时, 这会是一个很好的起点。

'最快的代码是从不执行的代码'。请试着按照以下步骤去剔除那些代价高昂的计算:

● 您打算使用该计算结果吗? 听起来有点可笑, 但这种可笑的事确实会发生--有时我们执行了计算但从未使用计算的结果

● 您现在需要该结果吗 ? 请在真正需要的时候再进行计算。在一些执行流程中有些结果永远不会被使用, 因此不必过早地计算。

● 您是否已经知道结果 ? 我们曾经见过程序中执行的许多代价高昂的计算, 其结果在两行代码前就已经知道。如果在程序执行流程的前期已经计算出了结果, 那么应该
  使该结果成为可重用的。

有的时候可能无法绕开该计算, 此时就必须完成它。'那么现在的挑战就是加快计算速度':

● 该计算是否过于通用 ?  您的实现只需要跟该领域要求的一样灵活就行, 而无须奢求。'可以充分利用简化的假设以降低灵活性来增加速度'

● 一些灵活性隐藏在库的函数调用中。通过实现库调用的自定义版本可以提升速度。不过，这些库调用必须是被频繁调用的，否则您的努力将得不到明显效果。熟悉您所使用的库和
  系统调用中隐藏的代价。

● '尽量减少内存管理调用的数量'。在绝大多数编译器中, 这些调用的代价都是非常高的

● 如果考虑所有可能的输入数据, 则可以发现 20% 的数据在 80% 时间里出现。因此, 应当以牺牲其他不经常出现的场景为代价来提高典型输入的处理速度

● 缓存、RAM 和磁盘访问的速度差异很明显。'应该多编写缓存友好的代码'






